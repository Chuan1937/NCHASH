{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NCHASH Test Suite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, '/home/chuan/Code/NCHASH')\n",
    "\n",
    "from nchash import driver, core, uncertainty, utils, io\n",
    "\n",
    "HASH_DIR = '/home/chuan/Code/NCHASH/HASH_v1.2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic Functionality Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Testing basic functionality...\")\n",
    "\n",
    "# Test cross product\n",
    "v1 = np.array([1.0, 0.0, 0.0])\n",
    "v2 = np.array([0.0, 1.0, 0.0])\n",
    "result = utils.cross_product(v1, v2)\n",
    "expected = np.array([0.0, 0.0, 1.0])\n",
    "assert np.allclose(result, expected), f\"Cross product failed: {result} != {expected}\"\n",
    "print(\"  [OK] Cross product\")\n",
    "\n",
    "# Test spherical to Cartesian conversion\n",
    "x, y, z = utils.to_cartesian(0.0, 0.0, 1.0)  # Straight up\n",
    "assert abs(x) < 1e-10 and abs(y) < 1e-10 and abs(z + 1.0) < 1e-10\n",
    "\n",
    "x, y, z = utils.to_cartesian(90.0, 0.0, 1.0)  # Horizontal, north\n",
    "assert abs(x - 1.0) < 1e-10 and abs(y) < 1e-10 and abs(z) < 1e-10\n",
    "print(\"  [OK] Spherical to Cartesian\")\n",
    "\n",
    "# Test fault plane coordinate conversion\n",
    "fnorm, slip = utils.fp_coord_angles_to_vectors(0.0, 90.0, 0.0)\n",
    "s, d, r = utils.fp_coord_vectors_to_angles(fnorm, slip)\n",
    "assert abs(s) < 1.0 or abs(abs(s) - 360.0) < 1.0\n",
    "assert abs(d - 90.0) < 1.0\n",
    "print(\"  [OK] Fault plane coordinates\")\n",
    "\n",
    "print(\"\\nAll basic tests passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Grid Search Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Testing grid search algorithm...\")\n",
    "\n",
    "# Create synthetic test case: pure strike-slip\n",
    "fnorm_ref, slip_ref = utils.fp_coord_angles_to_vectors(0.0, 90.0, 0.0)\n",
    "\n",
    "npol = 20\n",
    "np.random.seed(42)\n",
    "p_azi = np.random.uniform(0, 360, npol)\n",
    "p_the = np.random.uniform(20, 160, npol)\n",
    "p_pol = np.zeros(npol, dtype=np.int32)\n",
    "p_qual = np.zeros(npol, dtype=np.int32)\n",
    "\n",
    "for i in range(npol):\n",
    "    theta = p_the[i] * utils.DEG_TO_RAD\n",
    "    phi = p_azi[i] * utils.DEG_TO_RAD\n",
    "    p_a1 = np.sin(theta) * np.cos(phi)\n",
    "    p_a2 = np.sin(theta) * np.sin(phi)\n",
    "    p_a3 = -np.cos(theta)\n",
    "    p_b1 = (slip_ref[0] * p_a1 + slip_ref[1] * p_a2 + slip_ref[2] * p_a3)\n",
    "    p_b3 = (fnorm_ref[0] * p_a1 + fnorm_ref[1] * p_a2 + fnorm_ref[2] * p_a3)\n",
    "    p_pol[i] = 1 if p_b1 * p_b3 > 0 else -1\n",
    "\n",
    "# Add 10% noise\n",
    "n_noise = int(npol * 0.1)\n",
    "noise_idx = np.random.choice(npol, n_noise, replace=False)\n",
    "p_pol[noise_idx] = -p_pol[noise_idx]\n",
    "\n",
    "# Run grid search\n",
    "p_azi_mc = np.tile(p_azi.reshape(-1, 1), (1, 10))\n",
    "p_the_mc = np.tile(p_the.reshape(-1, 1), (1, 10))\n",
    "\n",
    "result = core.focalmc(\n",
    "    p_azi_mc, p_the_mc, p_pol, p_qual,\n",
    "    npol, 10, dang=10.0, maxout=100, nextra=2,\n",
    "    ntotal=max(int(npol * 0.15), 2)\n",
    ")\n",
    "\n",
    "print(f\"  Found {result['nf']} acceptable mechanisms\")\n",
    "\n",
    "if result['nf'] > 0:\n",
    "    prob_result = uncertainty.mech_prob(\n",
    "        result['nf'], result['faults'], result['slips'],\n",
    "        cangle=45.0, prob_max=0.1\n",
    "    )\n",
    "    if prob_result['nsltn'] > 0:\n",
    "        print(f\"  Input:  strike=0, dip=90, rake=0\")\n",
    "        print(f\"  Output: strike={prob_result['strike_avg'][0]:.1f}, \"\n",
    "              f\"dip={prob_result['dip_avg'][0]:.1f}, \"\n",
    "              f\"rake={prob_result['rake_avg'][0]:.1f}\")\n",
    "        print(\"  [OK] Grid search found acceptable mechanism\")\n",
    "else:\n",
    "    print(\"  [WARN] No acceptable mechanisms found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Comprehensive Tests vs Fortran"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tolerance\n",
    "STRIKE_TOL = 5.0\n",
    "DIP_TOL = 5.0\n",
    "RAKE_TOL = 10.0\n",
    "\n",
    "def parse_expected_output(filename):\n",
    "    \"\"\"Parse expected HASH output file.\"\"\"\n",
    "    expected_events = {}\n",
    "    with open(filename, 'r') as f:\n",
    "        for line in f:\n",
    "            if not line.strip():\n",
    "                continue\n",
    "            try:\n",
    "                event_id = line[0:16].strip()\n",
    "                if not event_id:\n",
    "                    continue\n",
    "                strike = int(line[129:133]) if line[129:133].strip() else 999\n",
    "                dip = int(line[134:137]) if line[134:137].strip() else 99\n",
    "                rake = int(line[138:142]) if line[138:142].strip() else 999\n",
    "                quality = line[159].strip()\n",
    "                is_valid = strike < 900 and dip < 90\n",
    "                expected_events[event_id] = {\n",
    "                    'strike': strike, 'dip': dip, 'rake': rake,\n",
    "                    'quality': quality, 'is_valid': is_valid\n",
    "                }\n",
    "            except:\n",
    "                continue\n",
    "    return expected_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_example_test(example_num):\n",
    "    \"\"\"Run a single example test.\"\"\"\n",
    "    inp_file = os.path.join(HASH_DIR, f'example{example_num}.inp')\n",
    "    expected_out_file = os.path.join(HASH_DIR, f'example{example_num}.out')\n",
    "    \n",
    "    if not os.path.exists(inp_file) or not os.path.exists(expected_out_file):\n",
    "        return None\n",
    "    \n",
    "    params = io.read_hash_input_file(inp_file)\n",
    "    \n",
    "    # Handle example 5 with multiple phase files\n",
    "    events = []\n",
    "    if example_num == 5:\n",
    "        with open(inp_file, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "        if len(lines) > 2:\n",
    "            for pf in [lines[1].strip(), lines[2].strip()]:\n",
    "                if pf and os.path.exists(os.path.join(HASH_DIR, pf)):\n",
    "                    for ev in io.read_phase_file(os.path.join(HASH_DIR, pf)):\n",
    "                        if ev['id'].strip() not in [e['id'].strip() for e in events]:\n",
    "                            events.append(ev)\n",
    "    else:\n",
    "        events = io.read_phase_file(os.path.join(HASH_DIR, params['phasefile']))\n",
    "    \n",
    "    stations = io.read_station_file(os.path.join(HASH_DIR, 'scsn.stations'))\n",
    "    pol_file = os.path.join(HASH_DIR, params['polfile'])\n",
    "    reversals = io.read_polarity_reversal_file(pol_file) if os.path.exists(pol_file) else {}\n",
    "    \n",
    "    expected = parse_expected_output(expected_out_file)\n",
    "    \n",
    "    matches, close, mismatches = 0, 0, 0\n",
    "    \n",
    "    for event in events:\n",
    "        event_id = event['id'].strip()\n",
    "        if event_id not in expected:\n",
    "            continue\n",
    "        \n",
    "        exp = expected[event_id]\n",
    "        result = driver.process_event(event, stations, reversals, params)\n",
    "        \n",
    "        if not exp['is_valid']:\n",
    "            if not result.get('success'):\n",
    "                matches += 1\n",
    "            else:\n",
    "                mismatches += 1\n",
    "        elif result.get('success'):\n",
    "            strike_ok = abs(result.get('strike_avg', 0) - exp['strike']) <= STRIKE_TOL\n",
    "            dip_ok = abs(result.get('dip_avg', 0) - exp['dip']) <= DIP_TOL\n",
    "            rake_ok = abs(result.get('rake_avg', 0) - exp['rake']) <= RAKE_TOL\n",
    "            \n",
    "            if strike_ok and dip_ok and rake_ok:\n",
    "                matches += 1\n",
    "            elif strike_ok and dip_ok:\n",
    "                close += 1\n",
    "            else:\n",
    "                mismatches += 1\n",
    "        else:\n",
    "            mismatches += 1\n",
    "    \n",
    "    total = matches + close + mismatches\n",
    "    return {'matches': matches, 'close': close, 'mismatches': mismatches, 'total': total}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"Running comprehensive tests (Python vs Fortran)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "all_results = {}\n",
    "\n",
    "for i in range(1, 6):\n",
    "    result = run_example_test(i)\n",
    "    if result:\n",
    "        all_results[f'example{i}'] = result\n",
    "        rate = (result['matches'] + result['close']) / result['total'] * 100 if result['total'] > 0 else 0\n",
    "        print(f\"\\nExample {i}: {result['matches']}/{result['total']} matches ({rate:.0f}%)\")\n",
    "        print(f\"  Matches: {result['matches']}, Close: {result['close']}, Mismatches: {result['mismatches']}\")\n",
    "    else:\n",
    "        print(f\"\\nExample {i}: Skipped (files not found)\")\n",
    "\n",
    "# Summary\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"OVERALL SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "total_matches = sum(r['matches'] for r in all_results.values())\n",
    "total_close = sum(r['close'] for r in all_results.values())\n",
    "total_events = sum(r['total'] for r in all_results.values())\n",
    "\n",
    "if total_events > 0:\n",
    "    overall_rate = (total_matches + total_close) / total_events * 100\n",
    "    print(f\"\\nTotal: {total_matches + total_close}/{total_events} ({overall_rate:.0f}%)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
